CartPole-v0:
  env: CartPole-v0
  max_epochs: 40
  batch_size: 32
  abstract_state_dim: 128
  optimizer:
    name: Adam
    params: { lr: !!python/float 1e-2 }
    # grad_clip_norm: 1.0
    # qnet_lr: !!python/float 5e-4
    # encoder_lr: !!python/float 5e-4
  gamma: 0.99
  sync_rate: 100
  replay_size: 1000
  warm_start_size: 1000
  eps_last_frame: 5000
  eps_start: 1.0
  eps_end: 0.01
  episode_length: 200
  max_episode_reward: 200
  planning_depth: 1
  is_atari: False
  is_custom: False
  replace: True
  logger_dir: lightning_dirs/cartpole
  plot_dir: /home/aayn/Programming/yarl/plots/cartpole

PongNoFrameskip-v4:
  env: PongNoFrameskip-v4
  max_epochs: 50000
  batch_size: 32
  abstract_state_dim: 100
  optimizer:
    name: Adam
    params: { lr: !!python/float 1e-4 }
    # qnet_lr: !!python/float 5e-4
    # encoder_lr: !!python/float 5e-4
  gamma: 0.99
  sync_rate: 1000
  replay_size: 10000
  warm_start_size: 10000
  eps_last_frame: 50000
  eps_start: 1.0
  eps_end: 0.01
  episode_length: 5000
  max_episode_reward: 21
  planning_depth: 0
  is_atari: True
  is_custom: False
  replace: True
  logger_dir: lightning_dirs/pong

SimpleMaze-v0:
  env: SimpleMaze-v0
  max_epochs: 500
  batch_size: 32
  abstract_state_dim: 2
  lr: !!python/float 5e-4
  optimizer:
    name: RMSprop
    params: { lr: !!python/float 5e-4 }
    grad_clip_norm: 1.0
    # qnet_lr: !!python/float 5e-4
    # encoder_lr: !!python/float 5e-4
  gamma: 0.99
  sync_rate: 1000 # freeze interval
  replay_size: 5000
  warm_start_size: 5000
  # TODO: Fix eps calculation for environment with/without reward
  eps_last_frame: 10000
  eps_start: 1.0
  eps_end: 0.01 # Random actions
  # End of TODO
  episode_length: 2000
  max_episode_reward: 0
  planning_depth: 2
  is_atari: False
  is_custom: True
  replace: True
  logger_dir: lightning_dirs/simple_mazev0
  plot_dir: /home/aayn/Programming/yarl/plots/test_goal_plots18_planning2_interp

SimpleMaze-v1:
  env: SimpleMaze-v1
  max_epochs: 500
  batch_size: 32
  abstract_state_dim: 2
  lr: !!python/float 5e-4
  optimizer:
    name: RMSprop
    params: { lr: !!python/float 5e-4 }
    grad_clip_norm: 1.0
    # qnet_lr: !!python/float 5e-4
    # encoder_lr: !!python/float 5e-4
  gamma: 0.99
  sync_rate: 1000 # freeze interval
  replay_size: 5000
  warm_start_size: 5000
  # TODO: Fix eps calculation for environment with/without reward
  eps_last_frame: 10000
  eps_start: 1.0
  eps_end: 0.01 # Random actions
  # End of TODO
  episode_length: 2000
  max_episode_reward: 0
  planning_depth: 2
  is_atari: False
  is_custom: True
  replace: True
  logger_dir: lightning_dirs/simple_mazev1
  plot_dir: /home/aayn/Programming/yarl/plots/test_goal_plots18_planning2_interp
