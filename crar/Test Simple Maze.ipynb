{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Simple Maze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments import SimpleMaze\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHER_DIM_OBS = True\n",
    "env = SimpleMaze(higher_dim_obs=HIGHER_DIM_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.  0.  0.7 0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.8 0.8 0.8 0.8 0.8 0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.  0.8 0.8 0.8 0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.  0.8 0.8 0.8 0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.  0.8 0.  0.8 0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  0.8 0.8 0.  0.8 0.8 0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]\n [1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. ]]\n"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=float('inf'))\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, reward, done, _ = env.step(2)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(torch.as_tensor(next_state[0]), torch.as_tensor(state[0])))\n",
    "# state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from crar_lightning import CRARLightning\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.patches import Circle, Rectangle\n",
    "from matplotlib.offsetbox import AnchoredOffsetbox, TextArea, DrawingArea, HPacker\n",
    "matplotlib.use(\"qt5agg\")\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.rcParams.keys()\n",
    "from environments import SimpleMaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'simple_maze_lightning/version_6/checkpoints/epoch=1.ckpt'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6e8e1de695c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCRARLightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'simple_maze_lightning/version_6/checkpoints/epoch=1.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/spinningup/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, tags_csv, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags_csv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/spinningup/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'simple_maze_lightning/version_6/checkpoints/epoch=1.ckpt'"
     ]
    }
   ],
   "source": [
    "pretrained_model = CRARLightning.load_from_checkpoint('simple_maze_lightning/version_6/checkpoints/epoch=1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maze(state):\n",
    "    matplotlib.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.figure()\n",
    "    c = plt.pcolor(state[0], edgecolors='k', linewidths=1, cmap='RdBu', vmin=0.0, vmax=1.0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGHER_DIM_OBS = True\n",
    "env = SimpleMaze(higher_dim_obs=HIGHER_DIM_OBS)\n",
    "state = env.reset()\n",
    "plot_maze(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state, *_ = env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_maze(next_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 1, 48, 48)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_inputs = env.all_possible_inputs()\n",
    "all_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = pretrained_model.agent.encode(all_inputs)\n",
    "exp1 = pretrained_model.replay_buffer.buffer[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "def most_recent(buffer, n: Union[None, int] = None):\n",
    "        if n is None:\n",
    "            return buffer[0]\n",
    "        buffer_copy, vals = buffer.copy(), []\n",
    "        for _ in range(n):\n",
    "            vals.append(buffer_copy.popleft())\n",
    "\n",
    "        return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1000 = list(\n",
    "    reversed(most_recent(pretrained_model.replay_buffer.buffer, 1000))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_maze_abstract_transitions(exp_seq, all_inputs, \n",
    "                                   all_abs_inputs, model):\n",
    "    matplotlib.rcParams['figure.figsize'] = (15, 15)\n",
    "    n = 1000\n",
    "    history = []\n",
    "    for i, (obs, *_) in enumerate(exp_seq):\n",
    "        history.append(obs)\n",
    "    history = np.array(history)\n",
    "    print(history.shape)\n",
    "    \n",
    "    abstract_states = model.agent.encode(history)\n",
    "    m = cm.ScalarMappable(cmap=cm.jet)\n",
    "    x, y = abstract_states.detach().cpu().numpy().T\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(r\"$X_1$\")\n",
    "    ax.set_ylabel(r\"$X_2$\")\n",
    "    \n",
    "    for i in range(n - 1):\n",
    "        predicted1 = model.agent.compute_transition(\n",
    "            abstract_states[i : i + 1],\n",
    "            torch.as_tensor([0], device='cuda')\n",
    "        ).detach().cpu().numpy()\n",
    "        \n",
    "        predicted2 = model.agent.compute_transition(\n",
    "            abstract_states[i : i + 1],\n",
    "            torch.as_tensor([1], device='cuda')\n",
    "        ).detach().cpu().numpy()\n",
    "        \n",
    "        predicted3 = model.agent.compute_transition(\n",
    "            abstract_states[i : i + 1],\n",
    "            torch.as_tensor([2], device='cuda')\n",
    "        ).detach().cpu().numpy()\n",
    "        \n",
    "        predicted4 = model.agent.compute_transition(\n",
    "            abstract_states[i : i + 1],\n",
    "            torch.as_tensor([3], device='cuda')\n",
    "        ).detach().cpu().numpy()\n",
    "        \n",
    "        ax.plot(\n",
    "            np.concatenate([x[i : i + 1], predicted1[0, :1]]),\n",
    "            np.concatenate([y[i : i + 1], predicted1[0, 1:2]]),\n",
    "            color=\"0.9\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "        \n",
    "        ax.plot(\n",
    "            np.concatenate([x[i : i + 1], predicted2[0, :1]]),\n",
    "            np.concatenate([y[i : i + 1], predicted2[0, 1:2]]),\n",
    "            color=\"0.65\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "        \n",
    "        ax.plot(\n",
    "            np.concatenate([x[i : i + 1], predicted3[0, :1]]),\n",
    "            np.concatenate([y[i : i + 1], predicted3[0, 1:2]]),\n",
    "            color=\"0.4\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "        \n",
    "        ax.plot(\n",
    "            np.concatenate([x[i : i + 1], predicted4[0, :1]]),\n",
    "            np.concatenate([y[i : i + 1], predicted4[0, 1:2]]),\n",
    "            color=\"0.15\",\n",
    "            alpha=0.75,\n",
    "        )\n",
    "    # Plot the dots at each time step depending on the action taken\n",
    "    length_block = [[0, 18], [18, 19], [19, 31]]\n",
    "    for i in range(3):\n",
    "        colors = ['blue', 'orange', 'green']\n",
    "        line3 = ax.scatter(\n",
    "                    all_abs_inputs[length_block[i][0] : length_block[i][1], 0],\n",
    "                    all_abs_inputs[length_block[i][0] : length_block[i][1], 1],\n",
    "                    c=colors[i],\n",
    "                    marker=\"x\",\n",
    "                    edgecolors=\"k\",\n",
    "                    alpha=0.5,\n",
    "                    s=100,\n",
    "                )\n",
    "    axes_lims = [ax.get_xlim(), ax.get_ylim()]\n",
    "    \n",
    "    box1b = TextArea(\n",
    "            \" Estimated transitions (action 0, 1, 2 and 3): \", textprops=dict(color=\"k\")\n",
    "        )\n",
    "    box2b = DrawingArea(90, 20, 0, 0)\n",
    "    el1b = Rectangle((5, 10), 15, 2, fc=\"0.9\", alpha=0.75)\n",
    "    el2b = Rectangle((25, 10), 15, 2, fc=\"0.65\", alpha=0.75)\n",
    "    el3b = Rectangle((45, 10), 15, 2, fc=\"0.4\", alpha=0.75)\n",
    "    el4b = Rectangle((65, 10), 15, 2, fc=\"0.15\", alpha=0.75)\n",
    "    box2b.add_artist(el1b)\n",
    "    box2b.add_artist(el2b)\n",
    "    box2b.add_artist(el3b)\n",
    "    box2b.add_artist(el4b)\n",
    "\n",
    "    boxb = HPacker(children=[box1b, box2b], align=\"center\", pad=0, sep=5)\n",
    "\n",
    "    anchored_box = AnchoredOffsetbox(\n",
    "        loc=3,\n",
    "        child=boxb,\n",
    "        pad=0.0,\n",
    "        frameon=True,\n",
    "        bbox_to_anchor=(0.0, 0.98),\n",
    "        bbox_transform=ax.transAxes,\n",
    "        borderpad=0.0,\n",
    "    )\n",
    "    ax.add_artist(anchored_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1, 48, 48)\n"
     ]
    }
   ],
   "source": [
    "plot_maze_abstract_transitions(exp1000, all_inputs, \n",
    "                               encoded_inputs.detach().cpu().numpy(),\n",
    "                               pretrained_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('spinningup': conda)",
   "language": "python",
   "name": "python361064bitspinningupcondaa7a9d9823c8d4a05886b1f3212fe475e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}